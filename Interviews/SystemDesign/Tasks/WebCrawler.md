# WebCrawler

## Description
A basic web crawler design should include the following features:

- Accept a list of URLs to visit and store their web pages.
- Extract any new URLs found in those web pages.
- Add these new URLs to the queue of URLs to visit.
- Repeat this process until the entire list of URLs has been crawled.

## Solution

![Solution](https://cdn-images-1.medium.com/max/900/1*F9QnGqmAMcXEr1lQeSiqVA.png)
[Full solution](https://www.enjoyalgorithms.com/blog/web-crawler/)